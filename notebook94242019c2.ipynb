{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":61542,"databundleVersionId":7516023,"sourceType":"competition"},{"sourceId":6266221,"sourceType":"datasetVersion","datasetId":3601853},{"sourceId":6921012,"sourceType":"datasetVersion","datasetId":3972872},{"sourceId":7249553,"sourceType":"datasetVersion","datasetId":4200168},{"sourceId":7286316,"sourceType":"datasetVersion","datasetId":4225280},{"sourceId":7286733,"sourceType":"datasetVersion","datasetId":4225558},{"sourceId":7299361,"sourceType":"datasetVersion","datasetId":4234408},{"sourceId":7314098,"sourceType":"datasetVersion","datasetId":4244321},{"sourceId":7409885,"sourceType":"datasetVersion","datasetId":4309789},{"sourceId":7430350,"sourceType":"datasetVersion","datasetId":4323931},{"sourceId":7437489,"sourceType":"datasetVersion","datasetId":4328709},{"sourceId":7438319,"sourceType":"datasetVersion","datasetId":4329193},{"sourceId":7444777,"sourceType":"datasetVersion","datasetId":4333279},{"sourceId":148861315,"sourceType":"kernelVersion"}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This notebook is by Anastasia Ruzmaikina. It was submitted to Kaggle Competition on LLM-Detect AI Generated Text","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-21T16:08:14.385689Z","iopub.execute_input":"2024-01-21T16:08:14.385968Z","iopub.status.idle":"2024-01-21T16:08:14.871724Z","shell.execute_reply.started":"2024-01-21T16:08:14.385942Z","shell.execute_reply":"2024-01-21T16:08:14.870799Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In recent years, large language models (LLMs) have become increasingly sophisticated, capable of generating text that is difficult to distinguish from human-written text. In this competition, we hope to foster open research and transparency on AI detection techniques applicable in the real world.\n\nThis competition challenges participants to develop a machine learning model that can accurately detect whether an essay was written by a student or an LLM. The competition dataset comprises a mix of student-written essays and essays generated by a variety of LLMs.\n\nCan you help build a model to identify which essay was written by middle and high school students, and which was written using a large language model? With the spread of LLMs, many people fear they will replace or alter work that would usually be done by humans. Educators are especially concerned about their impact on studentsâ€™ skill development, though many remain optimistic that LLMs will ultimately be a useful tool to help students improve their writing skills.\n\nThis notebook uses the dataset of AI written essays generated by the author using various LLMs and compares it with the dataset of human written essays provided in the competition. The model used to distinguish between human-written and AI-written essays is Llama-2-7b, and the best result on the competition test dataset is 85.1% accuracy.\n","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This notebook is adapted from the Notebook by Yuichi Tateno:  LLM detect AI comp Mistral-7B\nhttps://www.kaggle.com/code/hotchpotch/train-llm-detect-ai-comp-mistral-7b\n\nThe only major changes I have made were: use Llama2-7b-hf model from Kaggle datasets and to use my own generated.csv dataset for AI generated essays. In addition some small changes were made to the notebook.\n\nIn addition I have included the 'daight-pip' dataset from the Notebook by Min-Hsien Weng: TPU train Mistral 7b|Llama 2 detection\nhttps://www.kaggle.com/code/minhsienweng/tpu-train-mistral-7b-llama-2-detection","metadata":{}},{"cell_type":"code","source":"# Install package for inferences\n!pip install -qq --no-deps /kaggle/input/daigt-pip/peft-0.6.0-py3-none-any.whl\n!pip install -qq --no-deps /kaggle/input/daigt-pip/transformers-4.35.0-py3-none-any.whl\n!pip install -qq --no-deps /kaggle/input/daigt-pip/tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n!pip install -qq --no-deps /kaggle/input/daigt-pip/optimum-1.14.0-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:08:14.873931Z","iopub.execute_input":"2024-01-21T16:08:14.874857Z","iopub.status.idle":"2024-01-21T16:09:51.580600Z","shell.execute_reply.started":"2024-01-21T16:08:14.874813Z","shell.execute_reply":"2024-01-21T16:09:51.579350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -qq --no-deps /kaggle/input/llm-detect-pip/accelerate-0.24.1-py3-none-any.whl\n!pip install -qq --no-deps /kaggle/input/llm-detect-pip/bitsandbytes-0.41.1-py3-none-any.whl\n","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:09:51.581990Z","iopub.execute_input":"2024-01-21T16:09:51.582303Z","iopub.status.idle":"2024-01-21T16:10:38.706026Z","shell.execute_reply.started":"2024-01-21T16:09:51.582277Z","shell.execute_reply":"2024-01-21T16:10:38.704630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from __future__ import annotations\n\nTARGET_MODEL = '/kaggle/input/llama2-7b-hf/Llama2-7b-hf'#\"mistralai/Mistral-7B-v0.1\"\n\nDEBUG = False","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:10:38.708974Z","iopub.execute_input":"2024-01-21T16:10:38.709337Z","iopub.status.idle":"2024-01-21T16:10:38.714483Z","shell.execute_reply.started":"2024-01-21T16:10:38.709307Z","shell.execute_reply":"2024-01-21T16:10:38.713484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# ====================================================\n# Directory settings\n# ====================================================\nfrom pathlib import Path\n\nOUTPUT_DIR = Path(\"./\")\nOUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n\nINPUT_DIR = Path(\"../input/\")","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:10:38.715939Z","iopub.execute_input":"2024-01-21T16:10:38.716244Z","iopub.status.idle":"2024-01-21T16:10:38.727497Z","shell.execute_reply.started":"2024-01-21T16:10:38.716210Z","shell.execute_reply":"2024-01-21T16:10:38.726624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ntrain_df = pd.read_csv(INPUT_DIR / \"llm-detect-ai-generated-text/train_essays.csv\", sep=',')\ntest_df = pd.read_csv(INPUT_DIR / \"llm-detect-ai-generated-text/test_essays.csv\", sep=',')\n#external_df = pd.read_csv('/kaggle/input/generated2/generated.csv', sep=',')\nexternal_df1 = pd.read_csv('/kaggle/input/generated-classes/generatedchat.csv', sep=',')\nexternal_df1 = external_df1.sample(600, random_state=42)\nexternal_df2 = pd.read_csv('/kaggle/input/generated-classes/generatedsumm.csv', sep=',')\nexternal_df2 = external_df2.sample(600, random_state=42)\nexternal_df3 = pd.read_csv('/kaggle/input/generated-llama/generatedLlama.csv')\nexternal_df4 = pd.read_csv('/kaggle/input/generated-llama/generatedLlama.csv')\nexternal_df5 = pd.read_csv('/kaggle/input/generated-llama/generatedLlama.csv')\nexternal_df6 = pd.read_csv('/kaggle/input/generated-gpt/SummaryGpt.csv')\n#external_df7 = pd.read_csv('/kaggle/input/generated-gpt/SummaryGpt.csv')\n#external_df8 = pd.read_csv('/kaggle/input/generated-gpt/SummaryGpt.csv')\nexternal_df9 = pd.read_csv('/kaggle/input/generated-gpt3-5/SummaryGpt3.5.csv')\nexternal_df6 = external_df6.drop('Unnamed: 0', axis=1)\n#external_df10 = pd.read_csv('/kaggle/input/generated-rnn/SummaryRNN.csv')\n#external_df10['text'] = external_df10['text'].apply(lambda x: x[2:-1])\n#external_df7 = external_df7.drop('Unnamed: 0', axis=1)\n#external_df8 = external_df8.drop('Unnamed: 0', axis=1)\nexternal_df11 = pd.read_csv(\"/kaggle/input/generated-llama2/SummaryLlama5.csv\")\n#external_df = pd.concat([external_df1,external_df2, external_df3, external_df4, external_df5], ignore_index = True) \n#external_df = pd.concat([external_df1,external_df2, external_df3, external_df4, external_df5, external_df9, external_df11], ignore_index = True) \nexternal_df = pd.concat([external_df1,external_df2, external_df3, external_df4, external_df5], ignore_index = True) \n#external_df = pd.concat([external_df1,external_df2, external_df3, external_df4, external_df5, external_df6, external_df7, external_df8], ignore_index = True) \n#external_df = pd.concat([external_df1,external_df2, external_df3, external_df4, external_df5, external_df6, external_df9], ignore_index = True) \n#external_df = pd.concat([external_df1,external_df2, external_df3, external_df4, external_df5, external_df6, external_df9, external_df10], ignore_index = True) \n\ntrain_prompts_df = pd.read_csv(INPUT_DIR / \"llm-detect-ai-generated-text/train_prompts.csv\", sep=',')\n\n# show shape\nprint(f'train_df.shape: {train_df.shape}')\nprint(f'test_df.shape: {test_df.shape}')\nprint(f'external_df.shape: {external_df.shape}')\nprint(f'train_prompts_df.shape: {train_prompts_df.shape}')","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:10:38.728743Z","iopub.execute_input":"2024-01-21T16:10:38.729033Z","iopub.status.idle":"2024-01-21T16:10:39.131487Z","shell.execute_reply.started":"2024-01-21T16:10:38.729007Z","shell.execute_reply":"2024-01-21T16:10:39.130362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q -U peft --no-index --find-links ../input/llm-detect-pip/\n!pip install -q -U accelerate --no-index --find-links ../input/llm-detect-pip/\n!pip install -q -U bitsandbytes --no-index --find-links ../input/llm-detect-pip/\n!pip install -q -U transformers --no-index --find-links ../input/llm-detect-pip/\n# Install package for inferences\n!pip install -qq --no-deps /kaggle/input/daigt-pip/peft-0.6.0-py3-none-any.whl\n!pip install -qq --no-deps /kaggle/input/daigt-pip/transformers-4.35.0-py3-none-any.whl\n!pip install -qq --no-deps /kaggle/input/daigt-pip/tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n!pip install -qq --no-deps /kaggle/input/daigt-pip/optimum-1.14.0-py3-none-any.whl\n!pip install -qq --no-deps /kaggle/input/llm-detect-pip/accelerate-0.24.1-py3-none-any.whl\n!pip install -qq --no-deps /kaggle/input/llm-detect-pip/bitsandbytes-0.41.1-py3-none-any.whl\n","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:10:39.132979Z","iopub.execute_input":"2024-01-21T16:10:39.133375Z","iopub.status.idle":"2024-01-21T16:13:40.509737Z","shell.execute_reply.started":"2024-01-21T16:10:39.133347Z","shell.execute_reply":"2024-01-21T16:13:40.508224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rename column generated to label\ntrain_df = train_df.rename(columns={'generated': 'label'})\ntest_df = test_df.rename(columns={'generated': 'label'})\nexternal_df = external_df.rename(columns={'generated': 'label'})\n","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:13:40.511894Z","iopub.execute_input":"2024-01-21T16:13:40.512562Z","iopub.status.idle":"2024-01-21T16:13:40.525178Z","shell.execute_reply.started":"2024-01-21T16:13:40.512523Z","shell.execute_reply":"2024-01-21T16:13:40.524339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#external_df6 = external_df6.drop('Unnamed: 0', axis=1)\n#external_df10.text[0]\n","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:13:40.526628Z","iopub.execute_input":"2024-01-21T16:13:40.526960Z","iopub.status.idle":"2024-01-21T16:13:40.536593Z","shell.execute_reply.started":"2024-01-21T16:13:40.526929Z","shell.execute_reply":"2024-01-21T16:13:40.535767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:13:40.541446Z","iopub.execute_input":"2024-01-21T16:13:40.542016Z","iopub.status.idle":"2024-01-21T16:13:40.556561Z","shell.execute_reply.started":"2024-01-21T16:13:40.541982Z","shell.execute_reply":"2024-01-21T16:13:40.555651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:13:40.557808Z","iopub.execute_input":"2024-01-21T16:13:40.558167Z","iopub.status.idle":"2024-01-21T16:13:40.577232Z","shell.execute_reply.started":"2024-01-21T16:13:40.558113Z","shell.execute_reply":"2024-01-21T16:13:40.576391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:13:40.578542Z","iopub.execute_input":"2024-01-21T16:13:40.578939Z","iopub.status.idle":"2024-01-21T16:13:40.587201Z","shell.execute_reply.started":"2024-01-21T16:13:40.578916Z","shell.execute_reply":"2024-01-21T16:13:40.586252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"external_df.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:13:40.588597Z","iopub.execute_input":"2024-01-21T16:13:40.589305Z","iopub.status.idle":"2024-01-21T16:13:40.598852Z","shell.execute_reply.started":"2024-01-21T16:13:40.589272Z","shell.execute_reply":"2024-01-21T16:13:40.597882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"external_df.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:13:40.599767Z","iopub.execute_input":"2024-01-21T16:13:40.600056Z","iopub.status.idle":"2024-01-21T16:13:40.613725Z","shell.execute_reply.started":"2024-01-21T16:13:40.600033Z","shell.execute_reply":"2024-01-21T16:13:40.612833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.concat([train_df, external_df])\ntrain_df = train_df.drop(['id','prompt_id'], axis=1)\ntrain_df.reset_index(inplace=True, drop=True)\nprint(f\"Train dataframe has shape: {train_df.shape}\")\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:13:40.615071Z","iopub.execute_input":"2024-01-21T16:13:40.615433Z","iopub.status.idle":"2024-01-21T16:13:40.630495Z","shell.execute_reply.started":"2024-01-21T16:13:40.615402Z","shell.execute_reply":"2024-01-21T16:13:40.629359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_df = train_df.sample(frac=0.1)\ntrain_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:13:40.631871Z","iopub.execute_input":"2024-01-21T16:13:40.632228Z","iopub.status.idle":"2024-01-21T16:13:40.639299Z","shell.execute_reply.started":"2024-01-21T16:13:40.632197Z","shell.execute_reply":"2024-01-21T16:13:40.638062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.value_counts(\"label\")","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:13:40.640535Z","iopub.execute_input":"2024-01-21T16:13:40.640967Z","iopub.status.idle":"2024-01-21T16:13:40.650387Z","shell.execute_reply.started":"2024-01-21T16:13:40.640936Z","shell.execute_reply":"2024-01-21T16:13:40.649519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nX = train_df.loc[:, train_df.columns != \"label\"]\ny = train_df.loc[:, train_df.columns == \"label\"]\n\nfor i, (train_index, valid_index) in enumerate(skf.split(X, y)):\n    train_df.loc[valid_index, \"fold\"] = i\n    \nprint(train_df.groupby(\"fold\")[\"label\"].value_counts())\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:13:40.651761Z","iopub.execute_input":"2024-01-21T16:13:40.652076Z","iopub.status.idle":"2024-01-21T16:13:40.680735Z","shell.execute_reply.started":"2024-01-21T16:13:40.652047Z","shell.execute_reply":"2024-01-21T16:13:40.679741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fold0 as valid\nvalid_df = train_df[train_df[\"fold\"] == 0]\ntrain_df = train_df[train_df[\"fold\"] != 0]\nprint(train_df.shape)\nprint(valid_df.shape)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:13:40.682140Z","iopub.execute_input":"2024-01-21T16:13:40.682825Z","iopub.status.idle":"2024-01-21T16:13:40.689880Z","shell.execute_reply.started":"2024-01-21T16:13:40.682792Z","shell.execute_reply":"2024-01-21T16:13:40.688922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load model with 4bit bnb\n\nfrom peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType # type: ignore\nfrom transformers import BitsAndBytesConfig\nimport torch\n\npeft_config = LoraConfig(\n    r=4,\n    lora_alpha=16,\n    lora_dropout=0.1,\n    bias=\"none\",\n    task_type=TaskType.SEQ_CLS,\n    inference_mode=False,\n    target_modules=[\n        \"q_proj\",\n        \"v_proj\"\n    ],\n)\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=torch.bfloat16\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:13:40.691014Z","iopub.execute_input":"2024-01-21T16:13:40.691724Z","iopub.status.idle":"2024-01-21T16:13:44.252185Z","shell.execute_reply.started":"2024-01-21T16:13:40.691697Z","shell.execute_reply":"2024-01-21T16:13:44.251329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, LlamaForSequenceClassification\n\ntokenizer = AutoTokenizer.from_pretrained(TARGET_MODEL, use_fast=False)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:13:44.253178Z","iopub.execute_input":"2024-01-21T16:13:44.253581Z","iopub.status.idle":"2024-01-21T16:13:44.521582Z","shell.execute_reply.started":"2024-01-21T16:13:44.253556Z","shell.execute_reply":"2024-01-21T16:13:44.520792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = LlamaForSequenceClassification.from_pretrained(\n    TARGET_MODEL,\n    num_labels=2,\n    quantization_config=bnb_config,\n    device_map={\"\":0}\n)\nbase_model.config.pretraining_tp = 1 # 1 is 7b\nbase_model.config.pad_token_id = tokenizer.pad_token_id","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:13:44.522656Z","iopub.execute_input":"2024-01-21T16:13:44.523092Z","iopub.status.idle":"2024-01-21T16:16:25.555159Z","shell.execute_reply.started":"2024-01-21T16:13:44.523066Z","shell.execute_reply":"2024-01-21T16:16:25.554168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_peft_model(base_model, peft_config)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:16:25.556419Z","iopub.execute_input":"2024-01-21T16:16:25.556723Z","iopub.status.idle":"2024-01-21T16:16:25.693700Z","shell.execute_reply.started":"2024-01-21T16:16:25.556697Z","shell.execute_reply":"2024-01-21T16:16:25.692929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.print_trainable_parameters()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:16:25.694909Z","iopub.execute_input":"2024-01-21T16:16:25.695366Z","iopub.status.idle":"2024-01-21T16:16:25.704487Z","shell.execute_reply.started":"2024-01-21T16:16:25.695328Z","shell.execute_reply":"2024-01-21T16:16:25.703522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#remove this for actual calculation  here we take a smaller sample of the dataframe to speed up \ntrain_df = train_df.sample(2000, random_state=42)  #2400\ndf2 = pd.DataFrame({'text': ['aaaaa bbbbb ccccc.', 'bbbbbb cccccc dddddd.', 'cccc dddd eeee.', 'dd ee ff.'], 'label': [1,1,1,1], 'fold': [1.0,2.0,3.0,4.0]} )\nfor i in range(50):\n    train_df = pd.concat([train_df,df2], ignore_index = True) \nprint(train_df.tail())\nprint(train_df.label.value_counts(), valid_df.label.value_counts())","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:16:25.705617Z","iopub.execute_input":"2024-01-21T16:16:25.705880Z","iopub.status.idle":"2024-01-21T16:16:25.747393Z","shell.execute_reply.started":"2024-01-21T16:16:25.705857Z","shell.execute_reply":"2024-01-21T16:16:25.746518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#remove this for actual calculation\n#df_sampled = df.sample(frac=0.4)\n#df_remaining = df.loc[~df.index.isin(df_sampled.index)]\n\nvalid_df1 = valid_df.sample(frac = 0.4, random_state=42)\nvalid_df = valid_df.loc[~valid_df.index.isin(valid_df1.index)]\nprint(train_df.shape)\nprint(valid_df.shape)\nprint(valid_df1.shape)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:16:25.748683Z","iopub.execute_input":"2024-01-21T16:16:25.749325Z","iopub.status.idle":"2024-01-21T16:16:25.758855Z","shell.execute_reply.started":"2024-01-21T16:16:25.749289Z","shell.execute_reply":"2024-01-21T16:16:25.757815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from transformers import pipeline\n#generator = pipeline('text-generation', model='gpt2')\n#generator(\"Hello world, continue... \")\n","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:16:25.760056Z","iopub.execute_input":"2024-01-21T16:16:25.760354Z","iopub.status.idle":"2024-01-21T16:16:25.766515Z","shell.execute_reply.started":"2024-01-21T16:16:25.760330Z","shell.execute_reply":"2024-01-21T16:16:25.765605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:16:25.772858Z","iopub.execute_input":"2024-01-21T16:16:25.773143Z","iopub.status.idle":"2024-01-21T16:16:25.785851Z","shell.execute_reply.started":"2024-01-21T16:16:25.773102Z","shell.execute_reply":"2024-01-21T16:16:25.784933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# datasets\nfrom datasets import Dataset\n\n# from pandas\ntrain_ds = Dataset.from_pandas(train_df)\nvalid_ds = Dataset.from_pandas(valid_df)\ntest_ds = Dataset.from_pandas(test_df)\nvalid_ds1 = Dataset.from_pandas(valid_df1)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:16:25.786960Z","iopub.execute_input":"2024-01-21T16:16:25.787315Z","iopub.status.idle":"2024-01-21T16:16:26.288145Z","shell.execute_reply.started":"2024-01-21T16:16:25.787280Z","shell.execute_reply":"2024-01-21T16:16:26.287332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_function(examples, max_length=512):\n    return tokenizer(examples[\"text\"], truncation=True, max_length=max_length, padding=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:16:26.289282Z","iopub.execute_input":"2024-01-21T16:16:26.289713Z","iopub.status.idle":"2024-01-21T16:16:26.294345Z","shell.execute_reply.started":"2024-01-21T16:16:26.289685Z","shell.execute_reply":"2024-01-21T16:16:26.293427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_tokenized_ds = train_ds.map(preprocess_function, batched=True)\nvalid_tokenized_ds = valid_ds.map(preprocess_function, batched=True)\ntest_tokenized_ds = test_ds.map(preprocess_function, batched=True)\nvalid_tokenized_ds1 = valid_ds1.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:16:26.295490Z","iopub.execute_input":"2024-01-21T16:16:26.295751Z","iopub.status.idle":"2024-01-21T16:16:41.836343Z","shell.execute_reply.started":"2024-01-21T16:16:26.295728Z","shell.execute_reply":"2024-01-21T16:16:41.835294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"longest\")","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:16:41.837786Z","iopub.execute_input":"2024-01-21T16:16:41.838174Z","iopub.status.idle":"2024-01-21T16:16:51.455047Z","shell.execute_reply.started":"2024-01-21T16:16:41.838116Z","shell.execute_reply":"2024-01-21T16:16:51.454179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nimport numpy as np\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    \n    accuracy_val = accuracy_score(labels, predictions)\n    roc_auc_val = roc_auc_score(labels, predictions)\n    \n    return {\n        \"accuracy\": accuracy_val,\n        \"roc_auc\": roc_auc_val,\n    }","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:16:51.456203Z","iopub.execute_input":"2024-01-21T16:16:51.456817Z","iopub.status.idle":"2024-01-21T16:16:51.462625Z","shell.execute_reply.started":"2024-01-21T16:16:51.456788Z","shell.execute_reply":"2024-01-21T16:16:51.461713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\nsteps = 5 if DEBUG else 20\n\ntraining_args = TrainingArguments(\n    output_dir=OUTPUT_DIR,\n    learning_rate=5e-4,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=16,\n    max_grad_norm=0.3,\n    optim='paged_adamw_32bit',\n    lr_scheduler_type=\"cosine\",\n    num_train_epochs=1,\n    weight_decay=0.01,\n    evaluation_strategy=\"steps\",\n    save_strategy=\"steps\",\n    load_best_model_at_end=True,\n    push_to_hub=False,\n    warmup_steps=steps,\n    eval_steps=steps,\n    logging_steps=steps,\n    report_to='none' # if DEBUG else 'wandb',\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_tokenized_ds,\n    eval_dataset=valid_tokenized_ds,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:16:51.463890Z","iopub.execute_input":"2024-01-21T16:16:51.464583Z","iopub.status.idle":"2024-01-21T16:17:50.048776Z","shell.execute_reply.started":"2024-01-21T16:16:51.464556Z","shell.execute_reply":"2024-01-21T16:17:50.047031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from shutil import rmtree\n\n#trainer.save_model(output_dir=str(OUTPUT_DIR))\n\n#for path in Path(training_args.output_dir).glob(\"checkpoint-*\"):\n    #if path.is_dir():\n        #rmtree(path)","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:17:50.049814Z","iopub.status.idle":"2024-01-21T16:17:50.050249Z","shell.execute_reply.started":"2024-01-21T16:17:50.050027Z","shell.execute_reply":"2024-01-21T16:17:50.050045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#this is to check if the predictions work on a known dataframe not previously seen by the model\npreds = trainer.predict(valid_tokenized_ds1)\nlogits = preds.predictions","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:17:50.052649Z","iopub.status.idle":"2024-01-21T16:17:50.053603Z","shell.execute_reply.started":"2024-01-21T16:17:50.053310Z","shell.execute_reply":"2024-01-21T16:17:50.053338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from scipy.special import expit as sigmoid\nimport numpy as np\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))  \nprobs = sigmoid(logits[:, 1])\nprobs.shape, probs[0:5]\n","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:17:50.054905Z","iopub.status.idle":"2024-01-21T16:17:50.056060Z","shell.execute_reply.started":"2024-01-21T16:17:50.055775Z","shell.execute_reply":"2024-01-21T16:17:50.055803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#this is to check if the predictions work on a known dataframe not previosly seen by the model\nvalid_df1['preds'] = probs\nvalid_df1","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:17:50.057644Z","iopub.status.idle":"2024-01-21T16:17:50.058551Z","shell.execute_reply.started":"2024-01-21T16:17:50.058266Z","shell.execute_reply":"2024-01-21T16:17:50.058294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count = valid_df1[(valid_df1['preds'] >= 0.5 ) & (valid_df1['label'] == 1)].shape[0] + valid_df1[(valid_df1['preds'] < 0.5 ) & (valid_df1['label'] == 0)].shape[0]\nprint(count, count/valid_df1.shape[0])","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:17:50.059861Z","iopub.status.idle":"2024-01-21T16:17:50.060395Z","shell.execute_reply.started":"2024-01-21T16:17:50.060103Z","shell.execute_reply":"2024-01-21T16:17:50.060156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#this is for the predictions on the test set\npreds = trainer.predict(test_tokenized_ds)#.predictions.astype(float)\nlogits = preds.predictions\n#print(preds)\n#preds = np.clip(preds, 0, 1)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:17:50.061822Z","iopub.status.idle":"2024-01-21T16:17:50.062342Z","shell.execute_reply.started":"2024-01-21T16:17:50.062057Z","shell.execute_reply":"2024-01-21T16:17:50.062080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from scipy.special import expit as sigmoid\nimport numpy as np\ndef sigmoid(x):\n    #if x > -100:\n        return 1 / (1 + np.exp(-x))  \n   # else:\n       # return 0\nprobs = sigmoid(logits[:, 1])\nprobs.shape, probs[0:5]\n","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:17:50.064825Z","iopub.status.idle":"2024-01-21T16:17:50.066004Z","shell.execute_reply.started":"2024-01-21T16:17:50.065715Z","shell.execute_reply":"2024-01-21T16:17:50.065744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(sigmoid(10))\nprint(sigmoid(-10))\nprint(sigmoid(-1001))","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:17:50.067760Z","iopub.status.idle":"2024-01-21T16:17:50.068284Z","shell.execute_reply.started":"2024-01-21T16:17:50.067998Z","shell.execute_reply":"2024-01-21T16:17:50.068021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#this is to provide the sample submission\nsub = pd.DataFrame()\ntest_df = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv')\n#sub['id'] = valid_df['id']\nsub['id'] = test_df['id']\nimport math\nsub['generated'] = probs\nsub['generated'] = sub['generated'].round(1)\nsub.to_csv('/kaggle/working/submission.csv', index=False)\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:17:50.069760Z","iopub.status.idle":"2024-01-21T16:17:50.070279Z","shell.execute_reply.started":"2024-01-21T16:17:50.069994Z","shell.execute_reply":"2024-01-21T16:17:50.070017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfs = pd.read_csv('/kaggle/working/submission.csv')\ndfs","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:17:50.071577Z","iopub.status.idle":"2024-01-21T16:17:50.072067Z","shell.execute_reply.started":"2024-01-21T16:17:50.071809Z","shell.execute_reply":"2024-01-21T16:17:50.071832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#del trainer, model, base_model","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:17:50.074302Z","iopub.status.idle":"2024-01-21T16:17:50.075375Z","shell.execute_reply.started":"2024-01-21T16:17:50.075072Z","shell.execute_reply":"2024-01-21T16:17:50.075099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cuda cache clear\n#import torch\n#torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-01-21T16:17:50.076699Z","iopub.status.idle":"2024-01-21T16:17:50.077613Z","shell.execute_reply.started":"2024-01-21T16:17:50.077335Z","shell.execute_reply":"2024-01-21T16:17:50.077362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}