{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-21T16:08:14.385968Z",
     "iopub.status.busy": "2024-01-21T16:08:14.385689Z",
     "iopub.status.idle": "2024-01-21T16:08:14.871724Z",
     "shell.execute_reply": "2024-01-21T16:08:14.870799Z",
     "shell.execute_reply.started": "2024-01-21T16:08:14.385942Z"
    }
   },
   "outputs": [],
   "source": [
    "# This notebook is by Anastasia Ruzmaikina. It was submitted to Kaggle Competition on LLM-Detect AI Generated Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In recent years, large language models (LLMs) have become increasingly sophisticated, capable of generating text that is difficult to distinguish from human-written text. In this competition, we hope to foster open research and transparency on AI detection techniques applicable in the real world.\n",
    "\n",
    "This competition challenges participants to develop a machine learning model that can accurately detect whether an essay was written by a student or an LLM. The competition dataset comprises a mix of student-written essays and essays generated by a variety of LLMs.\n",
    "\n",
    "Can you help build a model to identify which essay was written by middle and high school students, and which was written using a large language model? With the spread of LLMs, many people fear they will replace or alter work that would usually be done by humans. Educators are especially concerned about their impact on studentsâ€™ skill development, though many remain optimistic that LLMs will ultimately be a useful tool to help students improve their writing skills.\n",
    "\n",
    "This notebook uses the dataset of AI written essays generated by the author using various LLMs and compares it with the dataset of human written essays provided in the competition. The model used to distinguish between human-written and AI-written essays is Llama-2-7b, and the best result on the competition test dataset is 85.1% accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is adapted from the Notebook by Yuichi Tateno:  LLM detect AI comp Mistral-7B\n",
    "https://www.kaggle.com/code/hotchpotch/train-llm-detect-ai-comp-mistral-7b\n",
    "\n",
    "The only major changes I have made were: use Llama2-7b-hf model from Kaggle datasets and to use my own generated.csv dataset for AI generated essays. In addition some small changes were made to the notebook.\n",
    "\n",
    "In addition I have included the 'daight-pip' dataset from the Notebook by Min-Hsien Weng: TPU train Mistral 7b|Llama 2 detection\n",
    "https://www.kaggle.com/code/minhsienweng/tpu-train-mistral-7b-llama-2-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:08:14.874857Z",
     "iopub.status.busy": "2024-01-21T16:08:14.873931Z",
     "iopub.status.idle": "2024-01-21T16:09:51.580600Z",
     "shell.execute_reply": "2024-01-21T16:09:51.579350Z",
     "shell.execute_reply.started": "2024-01-21T16:08:14.874813Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install package for inferences\n",
    "!pip install -qq --no-deps /kaggle/input/daigt-pip/peft-0.6.0-py3-none-any.whl\n",
    "!pip install -qq --no-deps /kaggle/input/daigt-pip/transformers-4.35.0-py3-none-any.whl\n",
    "!pip install -qq --no-deps /kaggle/input/daigt-pip/tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "!pip install -qq --no-deps /kaggle/input/daigt-pip/optimum-1.14.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:09:51.582303Z",
     "iopub.status.busy": "2024-01-21T16:09:51.581990Z",
     "iopub.status.idle": "2024-01-21T16:10:38.706026Z",
     "shell.execute_reply": "2024-01-21T16:10:38.704630Z",
     "shell.execute_reply.started": "2024-01-21T16:09:51.582277Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -qq --no-deps /kaggle/input/llm-detect-pip/accelerate-0.24.1-py3-none-any.whl\n",
    "!pip install -qq --no-deps /kaggle/input/llm-detect-pip/bitsandbytes-0.41.1-py3-none-any.whl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:10:38.709337Z",
     "iopub.status.busy": "2024-01-21T16:10:38.708974Z",
     "iopub.status.idle": "2024-01-21T16:10:38.714483Z",
     "shell.execute_reply": "2024-01-21T16:10:38.713484Z",
     "shell.execute_reply.started": "2024-01-21T16:10:38.709307Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "TARGET_MODEL = '/kaggle/input/llama2-7b-hf/Llama2-7b-hf'#\"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:10:38.716244Z",
     "iopub.status.busy": "2024-01-21T16:10:38.715939Z",
     "iopub.status.idle": "2024-01-21T16:10:38.727497Z",
     "shell.execute_reply": "2024-01-21T16:10:38.726624Z",
     "shell.execute_reply.started": "2024-01-21T16:10:38.716210Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ====================================================\n",
    "# Directory settings\n",
    "# ====================================================\n",
    "from pathlib import Path\n",
    "\n",
    "OUTPUT_DIR = Path(\"./\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "INPUT_DIR = Path(\"../input/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:10:38.729033Z",
     "iopub.status.busy": "2024-01-21T16:10:38.728743Z",
     "iopub.status.idle": "2024-01-21T16:10:39.131487Z",
     "shell.execute_reply": "2024-01-21T16:10:39.130362Z",
     "shell.execute_reply.started": "2024-01-21T16:10:38.729007Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(INPUT_DIR / \"llm-detect-ai-generated-text/train_essays.csv\", sep=',')\n",
    "test_df = pd.read_csv(INPUT_DIR / \"llm-detect-ai-generated-text/test_essays.csv\", sep=',')\n",
    "#external_df = pd.read_csv('/kaggle/input/generated2/generated.csv', sep=',')\n",
    "external_df1 = pd.read_csv('/kaggle/input/generated-classes/generatedchat.csv', sep=',')\n",
    "external_df1 = external_df1.sample(600, random_state=42)\n",
    "external_df2 = pd.read_csv('/kaggle/input/generated-classes/generatedsumm.csv', sep=',')\n",
    "external_df2 = external_df2.sample(600, random_state=42)\n",
    "external_df3 = pd.read_csv('/kaggle/input/generated-llama/generatedLlama.csv')\n",
    "external_df4 = pd.read_csv('/kaggle/input/generated-llama/generatedLlama.csv')\n",
    "external_df5 = pd.read_csv('/kaggle/input/generated-llama/generatedLlama.csv')\n",
    "external_df6 = pd.read_csv('/kaggle/input/generated-gpt/SummaryGpt.csv')\n",
    "#external_df7 = pd.read_csv('/kaggle/input/generated-gpt/SummaryGpt.csv')\n",
    "#external_df8 = pd.read_csv('/kaggle/input/generated-gpt/SummaryGpt.csv')\n",
    "external_df9 = pd.read_csv('/kaggle/input/generated-gpt3-5/SummaryGpt3.5.csv')\n",
    "external_df6 = external_df6.drop('Unnamed: 0', axis=1)\n",
    "#external_df10 = pd.read_csv('/kaggle/input/generated-rnn/SummaryRNN.csv')\n",
    "#external_df10['text'] = external_df10['text'].apply(lambda x: x[2:-1])\n",
    "#external_df7 = external_df7.drop('Unnamed: 0', axis=1)\n",
    "#external_df8 = external_df8.drop('Unnamed: 0', axis=1)\n",
    "external_df11 = pd.read_csv(\"/kaggle/input/generated-llama2/SummaryLlama5.csv\")\n",
    "#external_df = pd.concat([external_df1,external_df2, external_df3, external_df4, external_df5], ignore_index = True) \n",
    "#external_df = pd.concat([external_df1,external_df2, external_df3, external_df4, external_df5, external_df9, external_df11], ignore_index = True) \n",
    "external_df = pd.concat([external_df1,external_df2, external_df3, external_df4, external_df5], ignore_index = True) \n",
    "#external_df = pd.concat([external_df1,external_df2, external_df3, external_df4, external_df5, external_df6, external_df7, external_df8], ignore_index = True) \n",
    "#external_df = pd.concat([external_df1,external_df2, external_df3, external_df4, external_df5, external_df6, external_df9], ignore_index = True) \n",
    "#external_df = pd.concat([external_df1,external_df2, external_df3, external_df4, external_df5, external_df6, external_df9, external_df10], ignore_index = True) \n",
    "\n",
    "train_prompts_df = pd.read_csv(INPUT_DIR / \"llm-detect-ai-generated-text/train_prompts.csv\", sep=',')\n",
    "\n",
    "# show shape\n",
    "print(f'train_df.shape: {train_df.shape}')\n",
    "print(f'test_df.shape: {test_df.shape}')\n",
    "print(f'external_df.shape: {external_df.shape}')\n",
    "print(f'train_prompts_df.shape: {train_prompts_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:10:39.133375Z",
     "iopub.status.busy": "2024-01-21T16:10:39.132979Z",
     "iopub.status.idle": "2024-01-21T16:13:40.509737Z",
     "shell.execute_reply": "2024-01-21T16:13:40.508224Z",
     "shell.execute_reply.started": "2024-01-21T16:10:39.133347Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q -U peft --no-index --find-links ../input/llm-detect-pip/\n",
    "!pip install -q -U accelerate --no-index --find-links ../input/llm-detect-pip/\n",
    "!pip install -q -U bitsandbytes --no-index --find-links ../input/llm-detect-pip/\n",
    "!pip install -q -U transformers --no-index --find-links ../input/llm-detect-pip/\n",
    "# Install package for inferences\n",
    "!pip install -qq --no-deps /kaggle/input/daigt-pip/peft-0.6.0-py3-none-any.whl\n",
    "!pip install -qq --no-deps /kaggle/input/daigt-pip/transformers-4.35.0-py3-none-any.whl\n",
    "!pip install -qq --no-deps /kaggle/input/daigt-pip/tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "!pip install -qq --no-deps /kaggle/input/daigt-pip/optimum-1.14.0-py3-none-any.whl\n",
    "!pip install -qq --no-deps /kaggle/input/llm-detect-pip/accelerate-0.24.1-py3-none-any.whl\n",
    "!pip install -qq --no-deps /kaggle/input/llm-detect-pip/bitsandbytes-0.41.1-py3-none-any.whl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:13:40.512562Z",
     "iopub.status.busy": "2024-01-21T16:13:40.511894Z",
     "iopub.status.idle": "2024-01-21T16:13:40.525178Z",
     "shell.execute_reply": "2024-01-21T16:13:40.524339Z",
     "shell.execute_reply.started": "2024-01-21T16:13:40.512523Z"
    }
   },
   "outputs": [],
   "source": [
    "# rename column generated to label\n",
    "train_df = train_df.rename(columns={'generated': 'label'})\n",
    "test_df = test_df.rename(columns={'generated': 'label'})\n",
    "external_df = external_df.rename(columns={'generated': 'label'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:13:40.526960Z",
     "iopub.status.busy": "2024-01-21T16:13:40.526628Z",
     "iopub.status.idle": "2024-01-21T16:13:40.536593Z",
     "shell.execute_reply": "2024-01-21T16:13:40.535767Z",
     "shell.execute_reply.started": "2024-01-21T16:13:40.526929Z"
    }
   },
   "outputs": [],
   "source": [
    "#external_df6 = external_df6.drop('Unnamed: 0', axis=1)\n",
    "#external_df10.text[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:13:40.542016Z",
     "iopub.status.busy": "2024-01-21T16:13:40.541446Z",
     "iopub.status.idle": "2024-01-21T16:13:40.556561Z",
     "shell.execute_reply": "2024-01-21T16:13:40.555651Z",
     "shell.execute_reply.started": "2024-01-21T16:13:40.541982Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:13:40.558167Z",
     "iopub.status.busy": "2024-01-21T16:13:40.557808Z",
     "iopub.status.idle": "2024-01-21T16:13:40.577232Z",
     "shell.execute_reply": "2024-01-21T16:13:40.576391Z",
     "shell.execute_reply.started": "2024-01-21T16:13:40.558113Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:13:40.578939Z",
     "iopub.status.busy": "2024-01-21T16:13:40.578542Z",
     "iopub.status.idle": "2024-01-21T16:13:40.587201Z",
     "shell.execute_reply": "2024-01-21T16:13:40.586252Z",
     "shell.execute_reply.started": "2024-01-21T16:13:40.578916Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:13:40.589305Z",
     "iopub.status.busy": "2024-01-21T16:13:40.588597Z",
     "iopub.status.idle": "2024-01-21T16:13:40.598852Z",
     "shell.execute_reply": "2024-01-21T16:13:40.597882Z",
     "shell.execute_reply.started": "2024-01-21T16:13:40.589272Z"
    }
   },
   "outputs": [],
   "source": [
    "external_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:13:40.600056Z",
     "iopub.status.busy": "2024-01-21T16:13:40.599767Z",
     "iopub.status.idle": "2024-01-21T16:13:40.613725Z",
     "shell.execute_reply": "2024-01-21T16:13:40.612833Z",
     "shell.execute_reply.started": "2024-01-21T16:13:40.600033Z"
    }
   },
   "outputs": [],
   "source": [
    "external_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:13:40.615433Z",
     "iopub.status.busy": "2024-01-21T16:13:40.615071Z",
     "iopub.status.idle": "2024-01-21T16:13:40.630495Z",
     "shell.execute_reply": "2024-01-21T16:13:40.629359Z",
     "shell.execute_reply.started": "2024-01-21T16:13:40.615402Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df, external_df])\n",
    "train_df = train_df.drop(['id','prompt_id'], axis=1)\n",
    "train_df.reset_index(inplace=True, drop=True)\n",
    "print(f\"Train dataframe has shape: {train_df.shape}\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:13:40.632228Z",
     "iopub.status.busy": "2024-01-21T16:13:40.631871Z",
     "iopub.status.idle": "2024-01-21T16:13:40.639299Z",
     "shell.execute_reply": "2024-01-21T16:13:40.638062Z",
     "shell.execute_reply.started": "2024-01-21T16:13:40.632197Z"
    }
   },
   "outputs": [],
   "source": [
    "#train_df = train_df.sample(frac=0.1)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:13:40.640967Z",
     "iopub.status.busy": "2024-01-21T16:13:40.640535Z",
     "iopub.status.idle": "2024-01-21T16:13:40.650387Z",
     "shell.execute_reply": "2024-01-21T16:13:40.649519Z",
     "shell.execute_reply.started": "2024-01-21T16:13:40.640936Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.value_counts(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:13:40.652076Z",
     "iopub.status.busy": "2024-01-21T16:13:40.651761Z",
     "iopub.status.idle": "2024-01-21T16:13:40.680735Z",
     "shell.execute_reply": "2024-01-21T16:13:40.679741Z",
     "shell.execute_reply.started": "2024-01-21T16:13:40.652047Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "X = train_df.loc[:, train_df.columns != \"label\"]\n",
    "y = train_df.loc[:, train_df.columns == \"label\"]\n",
    "\n",
    "for i, (train_index, valid_index) in enumerate(skf.split(X, y)):\n",
    "    train_df.loc[valid_index, \"fold\"] = i\n",
    "    \n",
    "print(train_df.groupby(\"fold\")[\"label\"].value_counts())\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:13:40.682825Z",
     "iopub.status.busy": "2024-01-21T16:13:40.682140Z",
     "iopub.status.idle": "2024-01-21T16:13:40.689880Z",
     "shell.execute_reply": "2024-01-21T16:13:40.688922Z",
     "shell.execute_reply.started": "2024-01-21T16:13:40.682792Z"
    }
   },
   "outputs": [],
   "source": [
    "# fold0 as valid\n",
    "valid_df = train_df[train_df[\"fold\"] == 0]\n",
    "train_df = train_df[train_df[\"fold\"] != 0]\n",
    "print(train_df.shape)\n",
    "print(valid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:13:40.691724Z",
     "iopub.status.busy": "2024-01-21T16:13:40.691014Z",
     "iopub.status.idle": "2024-01-21T16:13:44.252185Z",
     "shell.execute_reply": "2024-01-21T16:13:44.251329Z",
     "shell.execute_reply.started": "2024-01-21T16:13:40.691697Z"
    }
   },
   "outputs": [],
   "source": [
    "# load model with 4bit bnb\n",
    "\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType # type: ignore\n",
    "from transformers import BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=4,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"v_proj\"\n",
    "    ],\n",
    ")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:13:44.253581Z",
     "iopub.status.busy": "2024-01-21T16:13:44.253178Z",
     "iopub.status.idle": "2024-01-21T16:13:44.521582Z",
     "shell.execute_reply": "2024-01-21T16:13:44.520792Z",
     "shell.execute_reply.started": "2024-01-21T16:13:44.253556Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, LlamaForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(TARGET_MODEL, use_fast=False)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:13:44.523092Z",
     "iopub.status.busy": "2024-01-21T16:13:44.522656Z",
     "iopub.status.idle": "2024-01-21T16:16:25.555159Z",
     "shell.execute_reply": "2024-01-21T16:16:25.554168Z",
     "shell.execute_reply.started": "2024-01-21T16:13:44.523066Z"
    }
   },
   "outputs": [],
   "source": [
    "base_model = LlamaForSequenceClassification.from_pretrained(\n",
    "    TARGET_MODEL,\n",
    "    num_labels=2,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map={\"\":0}\n",
    ")\n",
    "base_model.config.pretraining_tp = 1 # 1 is 7b\n",
    "base_model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:16:25.556723Z",
     "iopub.status.busy": "2024-01-21T16:16:25.556419Z",
     "iopub.status.idle": "2024-01-21T16:16:25.693700Z",
     "shell.execute_reply": "2024-01-21T16:16:25.692929Z",
     "shell.execute_reply.started": "2024-01-21T16:16:25.556697Z"
    }
   },
   "outputs": [],
   "source": [
    "model = get_peft_model(base_model, peft_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:16:25.695366Z",
     "iopub.status.busy": "2024-01-21T16:16:25.694909Z",
     "iopub.status.idle": "2024-01-21T16:16:25.704487Z",
     "shell.execute_reply": "2024-01-21T16:16:25.703522Z",
     "shell.execute_reply.started": "2024-01-21T16:16:25.695328Z"
    }
   },
   "outputs": [],
   "source": [
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:16:25.705880Z",
     "iopub.status.busy": "2024-01-21T16:16:25.705617Z",
     "iopub.status.idle": "2024-01-21T16:16:25.747393Z",
     "shell.execute_reply": "2024-01-21T16:16:25.746518Z",
     "shell.execute_reply.started": "2024-01-21T16:16:25.705857Z"
    }
   },
   "outputs": [],
   "source": [
    "#remove this for actual calculation  here we take a smaller sample of the dataframe to speed up \n",
    "train_df = train_df.sample(2000, random_state=42)  #2400\n",
    "df2 = pd.DataFrame({'text': ['aaaaa bbbbb ccccc.', 'bbbbbb cccccc dddddd.', 'cccc dddd eeee.', 'dd ee ff.'], 'label': [1,1,1,1], 'fold': [1.0,2.0,3.0,4.0]} )\n",
    "for i in range(50):\n",
    "    train_df = pd.concat([train_df,df2], ignore_index = True) \n",
    "print(train_df.tail())\n",
    "print(train_df.label.value_counts(), valid_df.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:16:25.749325Z",
     "iopub.status.busy": "2024-01-21T16:16:25.748683Z",
     "iopub.status.idle": "2024-01-21T16:16:25.758855Z",
     "shell.execute_reply": "2024-01-21T16:16:25.757815Z",
     "shell.execute_reply.started": "2024-01-21T16:16:25.749289Z"
    }
   },
   "outputs": [],
   "source": [
    "#remove this for actual calculation\n",
    "#df_sampled = df.sample(frac=0.4)\n",
    "#df_remaining = df.loc[~df.index.isin(df_sampled.index)]\n",
    "\n",
    "valid_df1 = valid_df.sample(frac = 0.4, random_state=42)\n",
    "valid_df = valid_df.loc[~valid_df.index.isin(valid_df1.index)]\n",
    "print(train_df.shape)\n",
    "print(valid_df.shape)\n",
    "print(valid_df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:16:25.760354Z",
     "iopub.status.busy": "2024-01-21T16:16:25.760056Z",
     "iopub.status.idle": "2024-01-21T16:16:25.766515Z",
     "shell.execute_reply": "2024-01-21T16:16:25.765605Z",
     "shell.execute_reply.started": "2024-01-21T16:16:25.760330Z"
    }
   },
   "outputs": [],
   "source": [
    "#from transformers import pipeline\n",
    "#generator = pipeline('text-generation', model='gpt2')\n",
    "#generator(\"Hello world, continue... \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:16:25.773143Z",
     "iopub.status.busy": "2024-01-21T16:16:25.772858Z",
     "iopub.status.idle": "2024-01-21T16:16:25.785851Z",
     "shell.execute_reply": "2024-01-21T16:16:25.784933Z",
     "shell.execute_reply.started": "2024-01-21T16:16:25.773102Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:16:25.787315Z",
     "iopub.status.busy": "2024-01-21T16:16:25.786960Z",
     "iopub.status.idle": "2024-01-21T16:16:26.288145Z",
     "shell.execute_reply": "2024-01-21T16:16:26.287332Z",
     "shell.execute_reply.started": "2024-01-21T16:16:25.787280Z"
    }
   },
   "outputs": [],
   "source": [
    "# datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "# from pandas\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "valid_ds = Dataset.from_pandas(valid_df)\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "valid_ds1 = Dataset.from_pandas(valid_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:16:26.289713Z",
     "iopub.status.busy": "2024-01-21T16:16:26.289282Z",
     "iopub.status.idle": "2024-01-21T16:16:26.294345Z",
     "shell.execute_reply": "2024-01-21T16:16:26.293427Z",
     "shell.execute_reply.started": "2024-01-21T16:16:26.289685Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples, max_length=512):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, max_length=max_length, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:16:26.295751Z",
     "iopub.status.busy": "2024-01-21T16:16:26.295490Z",
     "iopub.status.idle": "2024-01-21T16:16:41.836343Z",
     "shell.execute_reply": "2024-01-21T16:16:41.835294Z",
     "shell.execute_reply.started": "2024-01-21T16:16:26.295728Z"
    }
   },
   "outputs": [],
   "source": [
    "train_tokenized_ds = train_ds.map(preprocess_function, batched=True)\n",
    "valid_tokenized_ds = valid_ds.map(preprocess_function, batched=True)\n",
    "test_tokenized_ds = test_ds.map(preprocess_function, batched=True)\n",
    "valid_tokenized_ds1 = valid_ds1.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:16:41.838174Z",
     "iopub.status.busy": "2024-01-21T16:16:41.837786Z",
     "iopub.status.idle": "2024-01-21T16:16:51.455047Z",
     "shell.execute_reply": "2024-01-21T16:16:51.454179Z",
     "shell.execute_reply.started": "2024-01-21T16:16:41.838116Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"longest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:16:51.456817Z",
     "iopub.status.busy": "2024-01-21T16:16:51.456203Z",
     "iopub.status.idle": "2024-01-21T16:16:51.462625Z",
     "shell.execute_reply": "2024-01-21T16:16:51.461713Z",
     "shell.execute_reply.started": "2024-01-21T16:16:51.456788Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    accuracy_val = accuracy_score(labels, predictions)\n",
    "    roc_auc_val = roc_auc_score(labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy_val,\n",
    "        \"roc_auc\": roc_auc_val,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T16:16:51.464583Z",
     "iopub.status.busy": "2024-01-21T16:16:51.463890Z",
     "iopub.status.idle": "2024-01-21T16:17:50.048776Z",
     "shell.execute_reply": "2024-01-21T16:17:50.047031Z",
     "shell.execute_reply.started": "2024-01-21T16:16:51.464556Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "steps = 5 if DEBUG else 20\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    learning_rate=5e-4,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=16,\n",
    "    max_grad_norm=0.3,\n",
    "    optim='paged_adamw_32bit',\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    warmup_steps=steps,\n",
    "    eval_steps=steps,\n",
    "    logging_steps=steps,\n",
    "    report_to='none' # if DEBUG else 'wandb',\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized_ds,\n",
    "    eval_dataset=valid_tokenized_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-21T16:17:50.049814Z",
     "iopub.status.idle": "2024-01-21T16:17:50.050249Z",
     "shell.execute_reply": "2024-01-21T16:17:50.050045Z",
     "shell.execute_reply.started": "2024-01-21T16:17:50.050027Z"
    }
   },
   "outputs": [],
   "source": [
    "#from shutil import rmtree\n",
    "\n",
    "#trainer.save_model(output_dir=str(OUTPUT_DIR))\n",
    "\n",
    "#for path in Path(training_args.output_dir).glob(\"checkpoint-*\"):\n",
    "    #if path.is_dir():\n",
    "        #rmtree(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-21T16:17:50.052649Z",
     "iopub.status.idle": "2024-01-21T16:17:50.053603Z",
     "shell.execute_reply": "2024-01-21T16:17:50.053338Z",
     "shell.execute_reply.started": "2024-01-21T16:17:50.053310Z"
    }
   },
   "outputs": [],
   "source": [
    "#this is to check if the predictions work on a known dataframe not previously seen by the model\n",
    "preds = trainer.predict(valid_tokenized_ds1)\n",
    "logits = preds.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-21T16:17:50.054905Z",
     "iopub.status.idle": "2024-01-21T16:17:50.056060Z",
     "shell.execute_reply": "2024-01-21T16:17:50.055803Z",
     "shell.execute_reply.started": "2024-01-21T16:17:50.055775Z"
    }
   },
   "outputs": [],
   "source": [
    "# from scipy.special import expit as sigmoid\n",
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))  \n",
    "probs = sigmoid(logits[:, 1])\n",
    "probs.shape, probs[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-21T16:17:50.057644Z",
     "iopub.status.idle": "2024-01-21T16:17:50.058551Z",
     "shell.execute_reply": "2024-01-21T16:17:50.058294Z",
     "shell.execute_reply.started": "2024-01-21T16:17:50.058266Z"
    }
   },
   "outputs": [],
   "source": [
    "#this is to check if the predictions work on a known dataframe not previosly seen by the model\n",
    "valid_df1['preds'] = probs\n",
    "valid_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-21T16:17:50.059861Z",
     "iopub.status.idle": "2024-01-21T16:17:50.060395Z",
     "shell.execute_reply": "2024-01-21T16:17:50.060156Z",
     "shell.execute_reply.started": "2024-01-21T16:17:50.060103Z"
    }
   },
   "outputs": [],
   "source": [
    "count = valid_df1[(valid_df1['preds'] >= 0.5 ) & (valid_df1['label'] == 1)].shape[0] + valid_df1[(valid_df1['preds'] < 0.5 ) & (valid_df1['label'] == 0)].shape[0]\n",
    "print(count, count/valid_df1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-21T16:17:50.061822Z",
     "iopub.status.idle": "2024-01-21T16:17:50.062342Z",
     "shell.execute_reply": "2024-01-21T16:17:50.062080Z",
     "shell.execute_reply.started": "2024-01-21T16:17:50.062057Z"
    }
   },
   "outputs": [],
   "source": [
    "#this is for the predictions on the test set\n",
    "preds = trainer.predict(test_tokenized_ds)#.predictions.astype(float)\n",
    "logits = preds.predictions\n",
    "#print(preds)\n",
    "#preds = np.clip(preds, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-21T16:17:50.064825Z",
     "iopub.status.idle": "2024-01-21T16:17:50.066004Z",
     "shell.execute_reply": "2024-01-21T16:17:50.065744Z",
     "shell.execute_reply.started": "2024-01-21T16:17:50.065715Z"
    }
   },
   "outputs": [],
   "source": [
    "# from scipy.special import expit as sigmoid\n",
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "    #if x > -100:\n",
    "        return 1 / (1 + np.exp(-x))  \n",
    "   # else:\n",
    "       # return 0\n",
    "probs = sigmoid(logits[:, 1])\n",
    "probs.shape, probs[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-21T16:17:50.067760Z",
     "iopub.status.idle": "2024-01-21T16:17:50.068284Z",
     "shell.execute_reply": "2024-01-21T16:17:50.068021Z",
     "shell.execute_reply.started": "2024-01-21T16:17:50.067998Z"
    }
   },
   "outputs": [],
   "source": [
    "print(sigmoid(10))\n",
    "print(sigmoid(-10))\n",
    "print(sigmoid(-1001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-21T16:17:50.069760Z",
     "iopub.status.idle": "2024-01-21T16:17:50.070279Z",
     "shell.execute_reply": "2024-01-21T16:17:50.070017Z",
     "shell.execute_reply.started": "2024-01-21T16:17:50.069994Z"
    }
   },
   "outputs": [],
   "source": [
    "#this is to provide the sample submission\n",
    "sub = pd.DataFrame()\n",
    "test_df = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv')\n",
    "#sub['id'] = valid_df['id']\n",
    "sub['id'] = test_df['id']\n",
    "import math\n",
    "sub['generated'] = probs\n",
    "sub['generated'] = sub['generated'].round(1)\n",
    "sub.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-21T16:17:50.071577Z",
     "iopub.status.idle": "2024-01-21T16:17:50.072067Z",
     "shell.execute_reply": "2024-01-21T16:17:50.071832Z",
     "shell.execute_reply.started": "2024-01-21T16:17:50.071809Z"
    }
   },
   "outputs": [],
   "source": [
    "dfs = pd.read_csv('/kaggle/working/submission.csv')\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-21T16:17:50.074302Z",
     "iopub.status.idle": "2024-01-21T16:17:50.075375Z",
     "shell.execute_reply": "2024-01-21T16:17:50.075099Z",
     "shell.execute_reply.started": "2024-01-21T16:17:50.075072Z"
    }
   },
   "outputs": [],
   "source": [
    "#del trainer, model, base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-21T16:17:50.076699Z",
     "iopub.status.idle": "2024-01-21T16:17:50.077613Z",
     "shell.execute_reply": "2024-01-21T16:17:50.077362Z",
     "shell.execute_reply.started": "2024-01-21T16:17:50.077335Z"
    }
   },
   "outputs": [],
   "source": [
    "# cuda cache clear\n",
    "#import torch\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7516023,
     "sourceId": 61542,
     "sourceType": "competition"
    },
    {
     "datasetId": 3601853,
     "sourceId": 6266221,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3972872,
     "sourceId": 6921012,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4200168,
     "sourceId": 7249553,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4225280,
     "sourceId": 7286316,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4225558,
     "sourceId": 7286733,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4234408,
     "sourceId": 7299361,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4244321,
     "sourceId": 7314098,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4309789,
     "sourceId": 7409885,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4323931,
     "sourceId": 7430350,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4328709,
     "sourceId": 7437489,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4329193,
     "sourceId": 7438319,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4333279,
     "sourceId": 7444777,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 148861315,
     "sourceType": "kernelVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
