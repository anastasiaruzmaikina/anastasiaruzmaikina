{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This notebook is by Anastasia Ruzmaikina for Kaggle Competition Contradictory, My Dear Watson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have two sentences, there are three ways they could be related: one could entail the other, one could contradict the other, or they could be unrelated. Natural Language Inferencing (NLI) is a popular NLP problem that involves determining how pairs of sentences (consisting of a premise and a hypothesis) are related.\n",
    "\n",
    "Your task is to create an NLI model that assigns labels of 0, 1, or 2 (corresponding to entailment, neutral, and contradiction) to pairs of premises and hypotheses. To make things more interesting, the train and test set include text in fifteen different languages!\n",
    "\n",
    "In this notebook, I use HuggingFace Deberta-V3-Multi to analyze how pairs of sentences are related. This notebook has 67.1% accuracy on the competition test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-07T20:15:28.250346Z",
     "iopub.status.busy": "2024-09-07T20:15:28.249911Z",
     "iopub.status.idle": "2024-09-07T20:28:29.883015Z",
     "shell.execute_reply": "2024-09-07T20:28:29.882049Z",
     "shell.execute_reply.started": "2024-09-07T20:15:28.250280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.16.1\n",
      "KerasNLP version: 0.14.4\n",
      "/kaggle/input/debertav3base/rust_model.ot\n",
      "/kaggle/input/debertav3base/spm.model\n",
      "/kaggle/input/debertav3base/config.json\n",
      "/kaggle/input/debertav3base/tf_model.h5\n",
      "/kaggle/input/debertav3base/tokenizer_config.json\n",
      "/kaggle/input/debertav3base/pytorch_model.bin\n",
      "/kaggle/input/contradictory-my-dear-watson/sample_submission.csv\n",
      "/kaggle/input/contradictory-my-dear-watson/train.csv\n",
      "/kaggle/input/contradictory-my-dear-watson/test.csv\n",
      "/kaggle/input/debertav3small/spm.model\n",
      "/kaggle/input/debertav3small/config.json\n",
      "/kaggle/input/debertav3small/README.md\n",
      "/kaggle/input/debertav3small/tf_model.h5\n",
      "/kaggle/input/debertav3small/tokenizer_config.json\n",
      "/kaggle/input/debertav3small/pytorch_model.bin\n",
      "/kaggle/input/pii-deberta-models/piirate-training-hall.png\n",
      "/kaggle/input/pii-deberta-models/piiratefisk.png\n",
      "/kaggle/input/pii-deberta-models/piirates-on-boat.png\n",
      "/kaggle/input/pii-deberta-models/hacker-piirates.png\n",
      "/kaggle/input/pii-deberta-models/piinguinos.png\n",
      "/kaggle/input/pii-deberta-models/cuerpo-de-piiranha-mixtral-v1/spm.model\n",
      "/kaggle/input/pii-deberta-models/cuerpo-de-piiranha-mixtral-v1/config.json\n",
      "/kaggle/input/pii-deberta-models/cuerpo-de-piiranha-mixtral-v1/training_args.bin\n",
      "/kaggle/input/pii-deberta-models/cuerpo-de-piiranha-mixtral-v1/tokenizer.json\n",
      "/kaggle/input/pii-deberta-models/cuerpo-de-piiranha-mixtral-v1/tokenizer_config.json\n",
      "/kaggle/input/pii-deberta-models/cuerpo-de-piiranha-mixtral-v1/model.safetensors\n",
      "/kaggle/input/pii-deberta-models/cuerpo-de-piiranha-mixtral-v1/special_tokens_map.json\n",
      "/kaggle/input/pii-deberta-models/cuerpo-de-piiranha-mixtral-v1/added_tokens.json\n",
      "/kaggle/input/pii-deberta-models/cola-de-piiranha/spm.model\n",
      "/kaggle/input/pii-deberta-models/cola-de-piiranha/config.json\n",
      "/kaggle/input/pii-deberta-models/cola-de-piiranha/training_args.bin\n",
      "/kaggle/input/pii-deberta-models/cola-de-piiranha/tokenizer.json\n",
      "/kaggle/input/pii-deberta-models/cola-de-piiranha/tokenizer_config.json\n",
      "/kaggle/input/pii-deberta-models/cola-de-piiranha/model.safetensors\n",
      "/kaggle/input/pii-deberta-models/cola-de-piiranha/special_tokens_map.json\n",
      "/kaggle/input/pii-deberta-models/cola-de-piiranha/added_tokens.json\n",
      "/kaggle/input/pii-deberta-models/cola-de-piiranha-mixtral-v1/spm.model\n",
      "/kaggle/input/pii-deberta-models/cola-de-piiranha-mixtral-v1/config.json\n",
      "/kaggle/input/pii-deberta-models/cola-de-piiranha-mixtral-v1/training_args.bin\n",
      "/kaggle/input/pii-deberta-models/cola-de-piiranha-mixtral-v1/tokenizer.json\n",
      "/kaggle/input/pii-deberta-models/cola-de-piiranha-mixtral-v1/tokenizer_config.json\n",
      "/kaggle/input/pii-deberta-models/cola-de-piiranha-mixtral-v1/model.safetensors\n",
      "/kaggle/input/pii-deberta-models/cola-de-piiranha-mixtral-v1/special_tokens_map.json\n",
      "/kaggle/input/pii-deberta-models/cola-de-piiranha-mixtral-v1/added_tokens.json\n",
      "/kaggle/input/pii-deberta-models/cabeza-de-piiranha-persuade_v0/spm.model\n",
      "/kaggle/input/pii-deberta-models/cabeza-de-piiranha-persuade_v0/config.json\n",
      "/kaggle/input/pii-deberta-models/cabeza-de-piiranha-persuade_v0/training_args.bin\n",
      "/kaggle/input/pii-deberta-models/cabeza-de-piiranha-persuade_v0/tokenizer.json\n",
      "/kaggle/input/pii-deberta-models/cabeza-de-piiranha-persuade_v0/tokenizer_config.json\n",
      "/kaggle/input/pii-deberta-models/cabeza-de-piiranha-persuade_v0/model.safetensors\n",
      "/kaggle/input/pii-deberta-models/cabeza-de-piiranha-persuade_v0/special_tokens_map.json\n",
      "/kaggle/input/pii-deberta-models/cabeza-de-piiranha-persuade_v0/added_tokens.json\n",
      "/kaggle/input/pii-deberta-models/piranha/spm.model\n",
      "/kaggle/input/pii-deberta-models/piranha/config.json\n",
      "/kaggle/input/pii-deberta-models/piranha/training_args.bin\n",
      "/kaggle/input/pii-deberta-models/piranha/tokenizer.json\n",
      "/kaggle/input/pii-deberta-models/piranha/tokenizer_config.json\n",
      "/kaggle/input/pii-deberta-models/piranha/model.safetensors\n",
      "/kaggle/input/pii-deberta-models/piranha/special_tokens_map.json\n",
      "/kaggle/input/pii-deberta-models/piranha/added_tokens.json\n",
      "/kaggle/input/pii-deberta-models/piiranha/spm.model\n",
      "/kaggle/input/pii-deberta-models/piiranha/config.json\n",
      "/kaggle/input/pii-deberta-models/piiranha/training_args.bin\n",
      "/kaggle/input/pii-deberta-models/piiranha/tokenizer.json\n",
      "/kaggle/input/pii-deberta-models/piiranha/tokenizer_config.json\n",
      "/kaggle/input/pii-deberta-models/piiranha/model.safetensors\n",
      "/kaggle/input/pii-deberta-models/piiranha/special_tokens_map.json\n",
      "/kaggle/input/pii-deberta-models/piiranha/added_tokens.json\n",
      "/kaggle/input/pii-deberta-models/cabeza-de-piiranha-mixtral-v1/spm.model\n",
      "/kaggle/input/pii-deberta-models/cabeza-de-piiranha-mixtral-v1/config.json\n",
      "/kaggle/input/pii-deberta-models/cabeza-de-piiranha-mixtral-v1/training_args.bin\n",
      "/kaggle/input/pii-deberta-models/cabeza-de-piiranha-mixtral-v1/tokenizer.json\n",
      "/kaggle/input/pii-deberta-models/cabeza-de-piiranha-mixtral-v1/tokenizer_config.json\n",
      "/kaggle/input/pii-deberta-models/cabeza-de-piiranha-mixtral-v1/model.safetensors\n",
      "/kaggle/input/pii-deberta-models/cabeza-de-piiranha-mixtral-v1/special_tokens_map.json\n",
      "/kaggle/input/pii-deberta-models/cabeza-de-piiranha-mixtral-v1/added_tokens.json\n",
      "/kaggle/input/pii-deberta-models/lakshyakh93_deberta_finetuned_pii/config.json\n",
      "/kaggle/input/pii-deberta-models/lakshyakh93_deberta_finetuned_pii/merges.txt\n",
      "/kaggle/input/pii-deberta-models/lakshyakh93_deberta_finetuned_pii/trainer_state.json\n",
      "/kaggle/input/pii-deberta-models/lakshyakh93_deberta_finetuned_pii/training_args.bin\n",
      "/kaggle/input/pii-deberta-models/lakshyakh93_deberta_finetuned_pii/README.md\n",
      "/kaggle/input/pii-deberta-models/lakshyakh93_deberta_finetuned_pii/tokenizer.json\n",
      "/kaggle/input/pii-deberta-models/lakshyakh93_deberta_finetuned_pii/vocab.json\n",
      "/kaggle/input/pii-deberta-models/lakshyakh93_deberta_finetuned_pii/tokenizer_config.json\n",
      "/kaggle/input/pii-deberta-models/lakshyakh93_deberta_finetuned_pii/gitattributes\n",
      "/kaggle/input/pii-deberta-models/lakshyakh93_deberta_finetuned_pii/pytorch_model.bin\n",
      "/kaggle/input/pii-deberta-models/lakshyakh93_deberta_finetuned_pii/scheduler.pt\n",
      "/kaggle/input/pii-deberta-models/lakshyakh93_deberta_finetuned_pii/special_tokens_map.json\n",
      "/kaggle/input/pii-deberta-models/lakshyakh93_deberta_finetuned_pii/optimizer.pt\n",
      "/kaggle/input/pii-deberta-models/lakshyakh93_deberta_finetuned_pii/rng_state.pth\n",
      "/kaggle/input/pii-deberta-models/lakshyakh93_deberta_finetuned_pii/added_tokens.json\n",
      "/kaggle/input/pii-deberta-models/deberta-v3-base-finetuned/train_results.json\n",
      "/kaggle/input/pii-deberta-models/deberta-v3-base-finetuned/spm.model\n",
      "/kaggle/input/pii-deberta-models/deberta-v3-base-finetuned/config.json\n",
      "/kaggle/input/pii-deberta-models/deberta-v3-base-finetuned/trainer_state.json\n",
      "/kaggle/input/pii-deberta-models/deberta-v3-base-finetuned/eval_results.json\n",
      "/kaggle/input/pii-deberta-models/deberta-v3-base-finetuned/training_args.bin\n",
      "/kaggle/input/pii-deberta-models/deberta-v3-base-finetuned/README.md\n",
      "/kaggle/input/pii-deberta-models/deberta-v3-base-finetuned/tokenizer.json\n",
      "/kaggle/input/pii-deberta-models/deberta-v3-base-finetuned/all_results.json\n",
      "/kaggle/input/pii-deberta-models/deberta-v3-base-finetuned/tokenizer_config.json\n",
      "/kaggle/input/pii-deberta-models/deberta-v3-base-finetuned/gitattributes\n",
      "/kaggle/input/pii-deberta-models/deberta-v3-base-finetuned/model.safetensors\n",
      "/kaggle/input/pii-deberta-models/deberta-v3-base-finetuned/special_tokens_map.json\n",
      "/kaggle/input/pii-deberta-models/deberta-v3-base-finetuned/added_tokens.json\n",
      "/kaggle/input/pii-deberta-models/deberta-v3-base-finetuned/onnx/spm.model\n",
      "/kaggle/input/pii-deberta-models/deberta-v3-base-finetuned/onnx/model.onnx\n",
      "/kaggle/input/pii-deberta-models/deberta-v3-base-finetuned/onnx/config.json\n",
      "/kaggle/input/pii-deberta-models/deberta-v3-base-finetuned/onnx/tokenizer.json\n",
      "/kaggle/input/pii-deberta-models/deberta-v3-base-finetuned/onnx/tokenizer_config.json\n",
      "/kaggle/input/pii-deberta-models/deberta-v3-base-finetuned/onnx/special_tokens_map.json\n",
      "/kaggle/input/pii-deberta-models/deberta-v3-base-finetuned/onnx/added_tokens.json\n",
      "/kaggle/input/pii-deberta-models/cola del piinguuino/spm.model\n",
      "/kaggle/input/pii-deberta-models/cola del piinguuino/config.json\n",
      "/kaggle/input/pii-deberta-models/cola del piinguuino/training_args.bin\n",
      "/kaggle/input/pii-deberta-models/cola del piinguuino/tokenizer.json\n",
      "/kaggle/input/pii-deberta-models/cola del piinguuino/tokenizer_config.json\n",
      "/kaggle/input/pii-deberta-models/cola del piinguuino/model.safetensors\n",
      "/kaggle/input/pii-deberta-models/cola del piinguuino/special_tokens_map.json\n",
      "/kaggle/input/pii-deberta-models/cola del piinguuino/added_tokens.json\n",
      "/kaggle/input/pii-deberta-models/cabeza-del-piinguuino/spm.model\n",
      "/kaggle/input/pii-deberta-models/cabeza-del-piinguuino/config.json\n",
      "/kaggle/input/pii-deberta-models/cabeza-del-piinguuino/training_args.bin\n",
      "/kaggle/input/pii-deberta-models/cabeza-del-piinguuino/tokenizer.json\n",
      "/kaggle/input/pii-deberta-models/cabeza-del-piinguuino/tokenizer_config.json\n",
      "/kaggle/input/pii-deberta-models/cabeza-del-piinguuino/model.safetensors\n",
      "/kaggle/input/pii-deberta-models/cabeza-del-piinguuino/special_tokens_map.json\n",
      "/kaggle/input/pii-deberta-models/cabeza-del-piinguuino/added_tokens.json\n",
      "/kaggle/input/pii-deberta-models/cabeza-de-piiranha/spm.model\n",
      "/kaggle/input/pii-deberta-models/cabeza-de-piiranha/config.json\n",
      "/kaggle/input/pii-deberta-models/cabeza-de-piiranha/training_args.bin\n",
      "/kaggle/input/pii-deberta-models/cabeza-de-piiranha/tokenizer.json\n",
      "/kaggle/input/pii-deberta-models/cabeza-de-piiranha/tokenizer_config.json\n",
      "/kaggle/input/pii-deberta-models/cabeza-de-piiranha/model.safetensors\n",
      "/kaggle/input/pii-deberta-models/cabeza-de-piiranha/special_tokens_map.json\n",
      "/kaggle/input/pii-deberta-models/cabeza-de-piiranha/added_tokens.json\n",
      "/kaggle/input/pii-deberta-models/cuerpo del piinguuino/spm.model\n",
      "/kaggle/input/pii-deberta-models/cuerpo del piinguuino/config.json\n",
      "/kaggle/input/pii-deberta-models/cuerpo del piinguuino/lcel.pickle\n",
      "/kaggle/input/pii-deberta-models/cuerpo del piinguuino/training_args.bin\n",
      "/kaggle/input/pii-deberta-models/cuerpo del piinguuino/tokenizer.json\n",
      "/kaggle/input/pii-deberta-models/cuerpo del piinguuino/tokenizer_config.json\n",
      "/kaggle/input/pii-deberta-models/cuerpo del piinguuino/model.safetensors\n",
      "/kaggle/input/pii-deberta-models/cuerpo del piinguuino/special_tokens_map.json\n",
      "/kaggle/input/pii-deberta-models/cuerpo del piinguuino/added_tokens.json\n",
      "/kaggle/input/pii-deberta-models/cuerpo-de-piiranha/spm.model\n",
      "/kaggle/input/pii-deberta-models/cuerpo-de-piiranha/config.json\n",
      "/kaggle/input/pii-deberta-models/cuerpo-de-piiranha/training_args.bin\n",
      "/kaggle/input/pii-deberta-models/cuerpo-de-piiranha/tokenizer.json\n",
      "/kaggle/input/pii-deberta-models/cuerpo-de-piiranha/tokenizer_config.json\n",
      "/kaggle/input/pii-deberta-models/cuerpo-de-piiranha/model.safetensors\n",
      "/kaggle/input/pii-deberta-models/cuerpo-de-piiranha/special_tokens_map.json\n",
      "/kaggle/input/pii-deberta-models/cuerpo-de-piiranha/added_tokens.json\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-large-mnli/deberta-large-mnli/config.json\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-large-mnli/deberta-large-mnli/merges.txt\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-large-mnli/deberta-large-mnli/README.md\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-large-mnli/deberta-large-mnli/vocab.json\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-large-mnli/deberta-large-mnli/tokenizer_config.json\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-large-mnli/deberta-large-mnli/bpe_encoder.bin\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-large-mnli/deberta-large-mnli/pytorch_model.bin\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-xlarge/deberta-xlarge/config.json\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-xlarge/deberta-xlarge/merges.txt\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-xlarge/deberta-xlarge/vocab.json\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-xlarge/deberta-xlarge/tokenizer_config.json\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-xlarge/deberta-xlarge/bpe_encoder.bin\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-xlarge/deberta-xlarge/pytorch_model.bin\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-base-mnli/deberta-base-mnli/config.json\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-base-mnli/deberta-base-mnli/merges.txt\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-base-mnli/deberta-base-mnli/vocab.json\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-base-mnli/deberta-base-mnli/tokenizer_config.json\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-base-mnli/deberta-base-mnli/bpe_encoder.bin\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-base-mnli/deberta-base-mnli/pytorch_model.bin\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-large/deberta-large/config.json\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-large/deberta-large/merges.txt\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-large/deberta-large/vocab.json\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-large/deberta-large/tokenizer_config.json\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-large/deberta-large/bpe_encoder.bin\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-large/deberta-large/pytorch_model.bin\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-base/deberta-base/config.json\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-base/deberta-base/merges.txt\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-base/deberta-base/vocab.json\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-base/deberta-base/tokenizer_config.json\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-base/deberta-base/bpe_encoder.bin\n",
      "/kaggle/input/huggingface-deberta-variants/deberta-base/deberta-base/pytorch_model.bin\n",
      "           id                                            premise  \\\n",
      "0  f4891fa23f     Кто? Она спросила его с неожиданным интересом.   \n",
      "1  e8b38c6175  Others are Zao (in Tohoku) and a number of res...   \n",
      "2  e0a29d673a  trying to keep grass alive during a summer on ...   \n",
      "3  26222ec767  so i guess my experience is is just with what ...   \n",
      "4  d0cf40f417  The Journal put the point succinctly to  Is an...   \n",
      "\n",
      "                                          hypothesis lang_abv language  label  \n",
      "0  Она спросила, как это сделать, так как с её то...       ru  Russian      1  \n",
      "1   There are a lot of resorts in the national park.       en  English      0  \n",
      "2  There was no cost in keeping the grass alive i...       en  English      2  \n",
      "3  They were able to be home rather than having t...       en  English      0  \n",
      "4  The Journal asked \"Is this a good political mo...       en  English      1  \n",
      "3030\n",
      "5195\n",
      "Dataset({\n",
      "    features: ['premise', 'hypothesis', 'language', 'label', 'input'],\n",
      "    num_rows: 3030\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313e1f2741ad4c37bf33e2d2c804b6f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3030 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'language', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 2575\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['premise', 'hypothesis', 'language', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 455\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb0e4b4e35a4d8283ec0964109a8e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5195 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at /kaggle/input/huggingface-deberta-variants/deberta-base-mnli/deberta-base-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5150' max='5150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5150/5150 11:28, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.042000</td>\n",
       "      <td>1.313533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.903500</td>\n",
       "      <td>1.399237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.64208984  0.06585693  0.12219238]\n",
      " [-0.82958984 -0.14208984  0.55029297]\n",
      " [ 6.14453125 -2.8359375  -3.31054688]\n",
      " ...\n",
      " [-1.38378906  2.61523438 -1.65722656]\n",
      " [ 6.375      -2.7265625  -3.66796875]\n",
      " [-2.54296875 -2.52539062  6.2109375 ]]\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "import keras_core as keras\n",
    "import keras\n",
    "import keras_nlp\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import requests\n",
    "from keras.activations import softmax\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"KerasNLP version:\", keras_nlp.__version__)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "df1 = pd.read_csv(\"/kaggle/input/contradictory-my-dear-watson/train.csv\")\n",
    "df2 = pd.read_csv(\"/kaggle/input/contradictory-my-dear-watson/train.csv\")\n",
    "df = df1 #pd.concat([df1, df2], axis=0)\n",
    "df= df.sample(frac =0.25)\n",
    "df_train = df.reset_index()\n",
    "df_train.drop(columns=['index'], inplace=True)\n",
    "print(df_train.head())\n",
    "df_test = pd.read_csv(\"/kaggle/input/contradictory-my-dear-watson/test.csv\")\n",
    "df_test.head()\n",
    "\n",
    "from datasets import load_dataset\n",
    "#ds = load_dataset('csv', data_files=['/kaggle/input/llm-detect-ai-generated-text/train_essays.csv', '/kaggle/input/generated2/generated.csv', '/kaggle/input/generated1/generated1.csv'])\n",
    "#print(ds)\n",
    "print(len(df_train))\n",
    "print(len(df_test))\n",
    "\n",
    "df_train['premise'] = df_train['premise'].str.lower()\n",
    "#df_train.set_index('id', inplace=True)\n",
    "#df_train['generated'] = df_train['generated'].map({1:'yes', 0:'no'})\n",
    "#df_train['prompt_id'] = df_train['prompt_id'].map({1:'electoral', 0:'cars'})\n",
    "df_train['premise'] = df_train['premise'].str.replace(\"#\", \"\")\n",
    "#df_train = df_train.sample(frac=0.8)\n",
    "df_test['premise'] = df_test['premise'].str.replace(\"#\", \"\" )\n",
    "df_test['premise'] = df_test['premise'].str.lower()\n",
    "df_train['hypothesis'] = df_train['hypothesis'].str.lower()\n",
    "df_train['hypothesis'] = df_train['hypothesis'].str.replace(\"#\", \"\")\n",
    "df_test['hypothesis'] = df_test['hypothesis'].str.replace(\"#\", \"\" )\n",
    "df_test['hypothesis'] = df_test['hypothesis'].str.lower()\n",
    "\n",
    "#df_train = df_train.sample(frac=0.8)\n",
    "#df_test['generated_text'] = df_test['generated'].map({1:'yes', 0:'no'})\n",
    "#df_test['prompt_id'] = df_test['prompt_id'].map({1:'electoral', 0:'cars'})\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset,DatasetDict\n",
    "df_train['input'] = 'TEXT1: '+ df_train.premise + ';  TEXT2: '+ df_train.hypothesis + ';'\n",
    "#'TEXT: ' + df_train.text + ';  ANC: '+ df_train.prompt_id# + '; ANC2: '+ df_train.id\n",
    "#TEXT2: ' + df_train.generated + ';\n",
    "df_train1 = df_train.drop(['id', 'lang_abv'], axis=1)#, 'language'\n",
    "ds = Dataset.from_pandas(df_train1)\n",
    "print(ds)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#from transformers import DebertaV3Model\n",
    "from transformers import AutoModelForSequenceClassification,AutoTokenizer\n",
    "from transformers import TextClassificationPipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments,Trainer\n",
    "model_nm = '/kaggle/input/huggingface-deberta-variants/deberta-base-mnli/deberta-base-mnli'  #'/kaggle/input/debertav3small'       #'/kaggle/input/debertav3small'\n",
    "tokz = AutoTokenizer.from_pretrained(model_nm)\n",
    "def tok_func(x): return tokz(x[\"input\"])\n",
    "tok_ds = ds.map(tok_func, batched=True)\n",
    "tok_ds = tok_ds.rename_columns({'label':'labels'})\n",
    "dds = tok_ds.train_test_split(0.15, seed=420)\n",
    "print(dds)\n",
    "df_test['input'] = 'TEXT1: ' + df_test.premise + '; TEXT2: ' +df_test.hypothesis + ';' #'TEXT: ' + df_test.text + '; ANC: ' + df_test.prompt_id#+ '; ANC2: '+ df_test.id\n",
    "df_test1 = df_test.drop(['id', 'lang_abv'], axis=1)\n",
    "eval_ds = Dataset.from_pandas(df_test1).map(tok_func, batched=True)\n",
    "bs = 1\n",
    "epochs = 2\n",
    "lr = 4.15e-6\n",
    "\n",
    "args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n",
    "    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n",
    "    num_train_epochs=epochs, weight_decay=0.01, report_to='none')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=3)\n",
    "\n",
    "trainer = Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n",
    "                  tokenizer=tokz)#, compute_metrics=compute_metrics\n",
    "trainer.train();\n",
    "#pipe = TextClassificationPipeline(model=model, tokenizer=tokz)\n",
    "#prediction = pipe(\"The text to predict\", return_all_scores=True)\n",
    "#print(prediction)\n",
    "preds = trainer.predict(eval_ds).predictions.astype(float)\n",
    "print(preds)\n",
    "preds = np.clip(preds, 0, 1)\n",
    "\n",
    "# Make predictions\n",
    "#predictions = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model (optional)\n",
    "#classifier.evaluate(X_test)\n",
    "submission = df_test.id.copy().to_frame()\n",
    "submission[\"prediction\"] = np.argmax(preds, axis=1)#classifier.predict(X_test)\n",
    "#submission = df_test.id.copy().to_frame()\n",
    "#submission[\"prediction\"] = np.argmax(predictions, axis=1)\n",
    "\n",
    "#submission[\"generated\"] = submission[\"generated\"].round(1)\n",
    "submission.to_csv(\"/kaggle/working/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T20:28:29.884963Z",
     "iopub.status.busy": "2024-09-07T20:28:29.884628Z",
     "iopub.status.idle": "2024-09-07T20:28:29.901588Z",
     "shell.execute_reply": "2024-09-07T20:28:29.900701Z",
     "shell.execute_reply.started": "2024-09-07T20:28:29.884928Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c6d58c3f69</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cefcc82292</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e98005252c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58518c10ba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c32b0d16df</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5190</th>\n",
       "      <td>5f90dd59b0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>f357a04e86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>1f0ea92118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5193</th>\n",
       "      <td>0407b48afb</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5194</th>\n",
       "      <td>16c2f2ab89</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5195 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  prediction\n",
       "0     c6d58c3f69           2\n",
       "1     cefcc82292           2\n",
       "2     e98005252c           0\n",
       "3     58518c10ba           0\n",
       "4     c32b0d16df           2\n",
       "...          ...         ...\n",
       "5190  5f90dd59b0           2\n",
       "5191  f357a04e86           1\n",
       "5192  1f0ea92118           1\n",
       "5193  0407b48afb           0\n",
       "5194  16c2f2ab89           2\n",
       "\n",
       "[5195 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv('/kaggle/working/submission.csv')\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-07T20:28:29.903457Z",
     "iopub.status.busy": "2024-09-07T20:28:29.902829Z",
     "iopub.status.idle": "2024-09-07T20:28:32.073933Z",
     "shell.execute_reply": "2024-09-07T20:28:32.071993Z",
     "shell.execute_reply.started": "2024-09-07T20:28:29.903413Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def remove_folder_contents(folder):\n",
    "    for the_file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                remove_folder_contents(file_path)\n",
    "                os.rmdir(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "folder_path = '/kaggle/working'\n",
    "remove_folder_contents(folder_path)\n",
    "#os.rmdir(folder_path)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 1408234,
     "sourceId": 21733,
     "sourceType": "competition"
    },
    {
     "datasetId": 1369875,
     "sourceId": 3201311,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2105211,
     "sourceId": 3502519,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2210196,
     "sourceId": 3693646,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4340749,
     "sourceId": 7803679,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
