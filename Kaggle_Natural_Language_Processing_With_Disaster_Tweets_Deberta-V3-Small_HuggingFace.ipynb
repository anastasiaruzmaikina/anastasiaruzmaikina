{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"},{"sourceId":3502519,"sourceType":"datasetVersion","datasetId":2105211}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This notebook is by Anastasia Ruzmaikina for Kaggle Competition Natural Language Processing With Disaster Tweets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-30T18:58:53.888025Z","iopub.execute_input":"2024-09-30T18:58:53.888430Z","iopub.status.idle":"2024-09-30T18:58:53.893124Z","shell.execute_reply.started":"2024-09-30T18:58:53.888385Z","shell.execute_reply":"2024-09-30T18:58:53.891673Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Twitter has become an important communication channel in times of emergency. The ubiquitousness of smartphones enables people to announce an emergency they‚Äôre observing in real-time. Because of this, more agencies are interested in programatically monitoring Twitter (i.e. disaster relief organizations and news agencies).\n\nBut, it‚Äôs not always clear whether a person‚Äôs words are actually announcing a disaster.\n\nIn this competition, you‚Äôre challenged to build a machine learning model that predicts which Tweets are about real disasters and which one‚Äôs aren‚Äôt. You‚Äôll have access to a dataset of 10,000 tweets that were hand classified.\n\n\nIn this notebook, I use Deberta-V3 from HuggingFace to classify tweets as disaster tweets and non-disaster tweets. This notebook is 81.5% accurate on the competition test dataset.","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ndf= df.sample(frac = 0.4)\ndf_train = df.reset_index()\ndf_test = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\ndf_train","metadata":{"execution":{"iopub.status.busy":"2024-09-07T19:46:42.861615Z","iopub.execute_input":"2024-09-07T19:46:42.861955Z","iopub.status.idle":"2024-09-07T19:46:42.925613Z","shell.execute_reply.started":"2024-09-07T19:46:42.861923Z","shell.execute_reply":"2024-09-07T19:46:42.924717Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"      index    id      keyword               location  \\\n0      2644  3796  destruction                    NaN   \n1      2227  3185       deluge                    NaN   \n2      5448  7769       police                     UK   \n3       132   191   aftershock                    NaN   \n4      6845  9810       trauma  Montgomery County, MD   \n...     ...   ...          ...                    ...   \n3040   1873  2692        crush             Everywhere   \n3041   5931  8471     screamed              18 ¬â√õ¬¢ CC   \n3042   2596  3725    destroyed    √å√èT: 6.4682,3.18287   \n3043   1717  2478     collided                    NaN   \n3044   6853  9822       trauma                    NaN   \n\n                                                   text  target  \n0     So you have a new weapon that can cause un-ima...       1  \n1     The f$&amp;@ing things I do for #GISHWHES Just...       0  \n2     DT @georgegalloway: RT @Galloway4Mayor: ¬â√õ√èThe...       1  \n3     Aftershock back to school kick off was great. ...       0  \n4     in response to trauma Children of Addicts deve...       0  \n...                                                 ...     ...  \n3040      sevenfigz has a crush: http://t.co/20B3PnQxMD       1  \n3041  Some kids going to leadership camp came into m...       0  \n3042  Flood: Two people dead 60 houses destroyed in ...       1  \n3043  The 2 cars right in front of me collided and I...       1  \n3044  Hiroshima: They told me to paint my story: Eig...       1  \n\n[3045 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2644</td>\n      <td>3796</td>\n      <td>destruction</td>\n      <td>NaN</td>\n      <td>So you have a new weapon that can cause un-ima...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2227</td>\n      <td>3185</td>\n      <td>deluge</td>\n      <td>NaN</td>\n      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5448</td>\n      <td>7769</td>\n      <td>police</td>\n      <td>UK</td>\n      <td>DT @georgegalloway: RT @Galloway4Mayor: ¬â√õ√èThe...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>132</td>\n      <td>191</td>\n      <td>aftershock</td>\n      <td>NaN</td>\n      <td>Aftershock back to school kick off was great. ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6845</td>\n      <td>9810</td>\n      <td>trauma</td>\n      <td>Montgomery County, MD</td>\n      <td>in response to trauma Children of Addicts deve...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3040</th>\n      <td>1873</td>\n      <td>2692</td>\n      <td>crush</td>\n      <td>Everywhere</td>\n      <td>sevenfigz has a crush: http://t.co/20B3PnQxMD</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3041</th>\n      <td>5931</td>\n      <td>8471</td>\n      <td>screamed</td>\n      <td>18 ¬â√õ¬¢ CC</td>\n      <td>Some kids going to leadership camp came into m...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3042</th>\n      <td>2596</td>\n      <td>3725</td>\n      <td>destroyed</td>\n      <td>√å√èT: 6.4682,3.18287</td>\n      <td>Flood: Two people dead 60 houses destroyed in ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3043</th>\n      <td>1717</td>\n      <td>2478</td>\n      <td>collided</td>\n      <td>NaN</td>\n      <td>The 2 cars right in front of me collided and I...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3044</th>\n      <td>6853</td>\n      <td>9822</td>\n      <td>trauma</td>\n      <td>NaN</td>\n      <td>Hiroshima: They told me to paint my story: Eig...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>3045 rows √ó 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom datasets import Dataset,DatasetDict\ndf_train['input'] = 'TEXT: '+ df_train.text + ';'\n#'TEXT: ' + df_train.text + ';  ANC: '+ df_train.prompt_id# + '; ANC2: '+ df_train.id\n#TEXT2: ' + df_train.generated + ';\ndf_train1 = df_train.drop(['id', 'keyword', 'location'], axis=1)#, 'language'\nds = Dataset.from_pandas(df_train1)\nprint(ds)\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n#from transformers import DebertaV3Model\nfrom transformers import AutoModelForSequenceClassification,AutoTokenizer\nfrom transformers import TextClassificationPipeline, AutoTokenizer, AutoModelForSequenceClassification\nfrom transformers import TrainingArguments,Trainer\nmodel_nm = '/kaggle/input/debertav3small' # '/kaggle/input/huggingface-deberta-variants/deberta-base-mnli/deberta-base-mnli'  #'/kaggle/input/debertav3small'       #'/kaggle/input/debertav3small'\ntokz = AutoTokenizer.from_pretrained(model_nm)\ndef tok_func(x): return tokz(x[\"input\"])\ntok_ds = ds.map(tok_func, batched=True)\ntok_ds = tok_ds.rename_columns({'target':'labels'})\ndds = tok_ds.train_test_split(0.15, seed=420)\nprint(dds)\ndf_test['input'] = 'TEXT: ' + df_test.text  + ';' #'TEXT: ' + df_test.text + '; ANC: ' + df_test.prompt_id#+ '; ANC2: '+ df_test.id\ndf_test1 = df_test.drop(['id',  'keyword', 'location'], axis=1)\neval_ds = Dataset.from_pandas(df_test1).map(tok_func, batched=True)\nbs = 1\nepochs = 2\nlr = 4.15e-6","metadata":{"execution":{"iopub.status.busy":"2024-09-07T19:46:42.926908Z","iopub.execute_input":"2024-09-07T19:46:42.927293Z","iopub.status.idle":"2024-09-07T19:46:44.748937Z","shell.execute_reply.started":"2024-09-07T19:46:42.927259Z","shell.execute_reply":"2024-09-07T19:46:44.748023Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['index', 'text', 'target', 'input'],\n    num_rows: 3045\n})\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:551: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3045 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"348a4552c645402db184bf2ba1ef5696"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['index', 'text', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 2588\n    })\n    test: Dataset({\n        features: ['index', 'text', 'labels', 'input', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 457\n    })\n})\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3263 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9670429c8ae4a43aefc24f3b54ec0ac"}},"metadata":{}}]},{"cell_type":"code","source":"args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n    num_train_epochs=epochs, weight_decay=0.01, report_to='none')\nmodel = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=3)\n\ntrainer = Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n                  tokenizer=tokz)#, compute_metrics=compute_metrics\ntrainer.train();\n#pipe = TextClassificationPipeline(model=model, tokenizer=tokz)\n#prediction = pipe(\"The text to predict\", return_all_scores=True)\n#print(prediction)\npreds = trainer.predict(eval_ds).predictions.astype(float)\nprint(preds)\npreds = np.clip(preds, 0, 1)\n\n# Make predictions\n#predictions = classifier.predict(X_test)\n\n# Evaluate the model (optional)\n#classifier.evaluate(X_test)\nsubmission = df_test.id.copy().to_frame()\nsubmission[\"target\"] = np.argmax(preds, axis=1)#classifier.predict(X_test)\n#submission = df_test.id.copy().to_frame()\n#submission[\"prediction\"] = np.argmax(predictions, axis=1)\n\n#submission[\"generated\"] = submission[\"generated\"].round(1)\n#submission.to_csv(\"/kaggle/working/submission.csv\", index=False)\nsample_submission = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")\nprint(sample_submission.head())\nsample_submission[\"target\"] = np.argmax(preds, axis=1)\nsample_submission.to_csv(\"submission.csv\", index=False)\nsample_submission.describe()","metadata":{"execution":{"iopub.status.busy":"2024-09-07T19:46:44.750799Z","iopub.execute_input":"2024-09-07T19:46:44.751119Z","iopub.status.idle":"2024-09-07T19:54:19.018413Z","shell.execute_reply.started":"2024-09-07T19:46:44.751086Z","shell.execute_reply":"2024-09-07T19:54:19.017436Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n  warnings.warn(\nSome weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/debertav3small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5176' max='5176' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5176/5176 07:06, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.948100</td>\n      <td>1.013741</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.801700</td>\n      <td>1.005341</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"[[-2.0546875   5.1171875  -3.72851562]\n [-1.76953125  5.07421875 -3.81640625]\n [-2.1015625   5.20703125 -3.6796875 ]\n ...\n [-2.20703125  5.3125     -3.68359375]\n [-2.04296875  5.2265625  -3.76171875]\n [-1.98144531  5.19140625 -3.75976562]]\n   id  target\n0   0       0\n1   2       0\n2   3       0\n3   9       0\n4  11       0\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                 id       target\ncount   3263.000000  3263.000000\nmean    5427.152927     0.372663\nstd     3146.427221     0.483588\nmin        0.000000     0.000000\n25%     2683.000000     0.000000\n50%     5500.000000     0.000000\n75%     8176.000000     1.000000\nmax    10875.000000     1.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3263.000000</td>\n      <td>3263.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5427.152927</td>\n      <td>0.372663</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3146.427221</td>\n      <td>0.483588</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2683.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5500.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>8176.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>10875.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sub = pd.read_csv('submission.csv')\nsub","metadata":{"execution":{"iopub.status.busy":"2024-09-07T19:54:19.019623Z","iopub.execute_input":"2024-09-07T19:54:19.019985Z","iopub.status.idle":"2024-09-07T19:54:19.031647Z","shell.execute_reply.started":"2024-09-07T19:54:19.019949Z","shell.execute_reply":"2024-09-07T19:54:19.030800Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"         id  target\n0         0       1\n1         2       1\n2         3       1\n3         9       1\n4        11       1\n...     ...     ...\n3258  10861       1\n3259  10865       1\n3260  10868       1\n3261  10874       1\n3262  10875       1\n\n[3263 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3258</th>\n      <td>10861</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3259</th>\n      <td>10865</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3260</th>\n      <td>10868</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3261</th>\n      <td>10874</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3262</th>\n      <td>10875</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>3263 rows √ó 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import os\n\ndef remove_folder_contents(folder):\n    for the_file in os.listdir(folder):\n        file_path = os.path.join(folder, the_file)\n        try:\n            if os.path.isfile(file_path):\n                os.unlink(file_path)\n            elif os.path.isdir(file_path):\n                remove_folder_contents(file_path)\n                os.rmdir(file_path)\n        except Exception as e:\n            print(e)\n\nfolder_path = '/kaggle/working'\n#remove_folder_contents(folder_path)\n#os.rmdir(folder_path)","metadata":{"execution":{"iopub.status.busy":"2024-09-07T19:54:19.032988Z","iopub.execute_input":"2024-09-07T19:54:19.033733Z","iopub.status.idle":"2024-09-07T19:54:21.233384Z","shell.execute_reply.started":"2024-09-07T19:54:19.033690Z","shell.execute_reply":"2024-09-07T19:54:21.231536Z"},"trusted":true},"execution_count":14,"outputs":[]}]}